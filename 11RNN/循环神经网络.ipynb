{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\develop\\python\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:\\\\study\\\\tensorflow\\\\data\\\\Tweets\\\\Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['airline_sentiment','text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'positive', 'negative'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.airline_sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    9178\n",
       "neutral     3099\n",
       "positive    2363\n",
       "Name: airline_sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.airline_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data[data.airline_sentiment == 'negative']\n",
    "data_p = data[data.airline_sentiment == 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data_n.iloc[:len(data_p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2363"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data_n,data_p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review'] = (data.airline_sentiment == 'positive').astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3193</td>\n",
       "      <td>@united broke my suitcase &amp;amp; refuses to giv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13855</td>\n",
       "      <td>@AmericanAir Didn't really need anything. Saw ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>@VirginAmerica thanks for gate checking my bag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1547</td>\n",
       "      <td>@united Appreciated, but in this case we waite...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3162</td>\n",
       "      <td>@united thanks for ruining my wedding annivers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7855</td>\n",
       "      <td>@JetBlue im in a session presented by one of y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3594</td>\n",
       "      <td>@united Funny thing happened, we arrived on ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>@united so you're telling me there is no numbe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021</td>\n",
       "      <td>@united still missing my luggage, was promised...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>@united lost bag on next flight. Didn't have t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review\n",
       "3193   @united broke my suitcase &amp; refuses to giv...       0\n",
       "13855  @AmericanAir Didn't really need anything. Saw ...       1\n",
       "264    @VirginAmerica thanks for gate checking my bag...       1\n",
       "1547   @united Appreciated, but in this case we waite...       0\n",
       "3162   @united thanks for ruining my wedding annivers...       0\n",
       "...                                                  ...     ...\n",
       "7855   @JetBlue im in a session presented by one of y...       1\n",
       "3594   @united Funny thing happened, we arrived on ou...       0\n",
       "650    @united so you're telling me there is no numbe...       0\n",
       "2021   @united still missing my luggage, was promised...       0\n",
       "1995   @united lost bag on next flight. Didn't have t...       0\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = re.compile('[A-Za-z]+|[!?,.()]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_text(text):\n",
    "    new_text = token.findall(text)\n",
    "    new_text = [word.lower() for word in new_text]\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data.text.apply(reg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3193</td>\n",
       "      <td>[united, broke, my, suitcase, amp, refuses, to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13855</td>\n",
       "      <td>[americanair, didn, t, really, need, anything,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>264</td>\n",
       "      <td>[virginamerica, thanks, for, gate, checking, m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1547</td>\n",
       "      <td>[united, appreciated, ,, but, in, this, case, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3162</td>\n",
       "      <td>[united, thanks, for, ruining, my, wedding, an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7855</td>\n",
       "      <td>[jetblue, im, in, a, session, presented, by, o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3594</td>\n",
       "      <td>[united, funny, thing, happened, ,, we, arrive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>[united, so, you, re, telling, me, there, is, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2021</td>\n",
       "      <td>[united, still, missing, my, luggage, ,, was, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1995</td>\n",
       "      <td>[united, lost, bag, on, next, flight, ., didn,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  review\n",
       "3193   [united, broke, my, suitcase, amp, refuses, to...       0\n",
       "13855  [americanair, didn, t, really, need, anything,...       1\n",
       "264    [virginamerica, thanks, for, gate, checking, m...       1\n",
       "1547   [united, appreciated, ,, but, in, this, case, ...       0\n",
       "3162   [united, thanks, for, ruining, my, wedding, an...       0\n",
       "...                                                  ...     ...\n",
       "7855   [jetblue, im, in, a, session, presented, by, o...       1\n",
       "3594   [united, funny, thing, happened, ,, we, arrive...       0\n",
       "650    [united, so, you, re, telling, me, there, is, ...       0\n",
       "2021   [united, still, missing, my, luggage, ,, was, ...       0\n",
       "1995   [united, lost, bag, on, next, flight, ., didn,...       0\n",
       "\n",
       "[4726 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = set()\n",
    "for text in data['text']:\n",
    "    for word in text:\n",
    "        word_set.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_word = len(word_set)\n",
    "max_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = dict((word,word_list.index(word)+1) for word in word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diane': 1,\n",
       " 'craving': 2,\n",
       " 'nwk': 3,\n",
       " 'neworleans': 4,\n",
       " 'newsbusiness': 5,\n",
       " 'cbarrows': 6,\n",
       " 'song': 7,\n",
       " 'sucked': 8,\n",
       " 'alavera': 9,\n",
       " 'calming': 10,\n",
       " 'black': 11,\n",
       " 'unexpactable': 12,\n",
       " 'profit': 13,\n",
       " 'sibling': 14,\n",
       " 'you': 15,\n",
       " 'watching': 16,\n",
       " 'playlist': 17,\n",
       " 'much': 18,\n",
       " 'deal': 19,\n",
       " 'sun': 20,\n",
       " 'chn': 21,\n",
       " 'pairings': 22,\n",
       " 'individual': 23,\n",
       " 'cb': 24,\n",
       " 'washington': 25,\n",
       " 'frigid': 26,\n",
       " 'suprlfoi': 27,\n",
       " 'eq': 28,\n",
       " 'connolly': 29,\n",
       " 'mkpognntyc': 30,\n",
       " 'grandcanyon': 31,\n",
       " 'mysteriously': 32,\n",
       " 'daily': 33,\n",
       " 'showing': 34,\n",
       " 'believing': 35,\n",
       " 'tpdkqulm': 36,\n",
       " 'rescued': 37,\n",
       " 'let': 38,\n",
       " 'char': 39,\n",
       " 'strange': 40,\n",
       " 'seg': 41,\n",
       " 'responds': 42,\n",
       " 'tbsjquw': 43,\n",
       " 'keepitmovin': 44,\n",
       " 'suprise': 45,\n",
       " 'problems': 46,\n",
       " 'tulsa': 47,\n",
       " 'hurry': 48,\n",
       " 'mortified': 49,\n",
       " 'she': 50,\n",
       " 'where': 51,\n",
       " 'sarcastically': 52,\n",
       " 'sheila': 53,\n",
       " 'trap': 54,\n",
       " 'aggravation': 55,\n",
       " 'kkedjnrtwo': 56,\n",
       " 'pricey': 57,\n",
       " 'corny': 58,\n",
       " 'market': 59,\n",
       " 'whats': 60,\n",
       " 'voided': 61,\n",
       " 'miles': 62,\n",
       " 'lifeline': 63,\n",
       " 'rick': 64,\n",
       " 'displeasure': 65,\n",
       " 'offensive': 66,\n",
       " 'packages': 67,\n",
       " 'assurance': 68,\n",
       " 'bonnie': 69,\n",
       " 'classed': 70,\n",
       " 'cross': 71,\n",
       " 'arrogant': 72,\n",
       " 'hr': 73,\n",
       " 'compare': 74,\n",
       " 'flightedflight': 75,\n",
       " 'epic': 76,\n",
       " 'trgemtebz': 77,\n",
       " 'star': 78,\n",
       " 'lifeisgood': 79,\n",
       " 'responded': 80,\n",
       " 'usurious': 81,\n",
       " 'network': 82,\n",
       " 'crisis': 83,\n",
       " 'packermama': 84,\n",
       " 'shitty': 85,\n",
       " 'rated': 86,\n",
       " 'kisses': 87,\n",
       " 'simplify': 88,\n",
       " 'weight': 89,\n",
       " 'jedediahbila': 90,\n",
       " 'prioritize': 91,\n",
       " 'metal': 92,\n",
       " 'sends': 93,\n",
       " 'drinks': 94,\n",
       " 'emergency': 95,\n",
       " 'hourdelay': 96,\n",
       " 'throwback': 97,\n",
       " 'attentiveness': 98,\n",
       " 'baimes': 99,\n",
       " 'ndary': 100,\n",
       " 'outside': 101,\n",
       " 'wedding': 102,\n",
       " 'shv': 103,\n",
       " 'newark': 104,\n",
       " 'digital': 105,\n",
       " 'schedule': 106,\n",
       " 'activate': 107,\n",
       " 'stream': 108,\n",
       " 'exactly': 109,\n",
       " 'unbelievably': 110,\n",
       " 'copy': 111,\n",
       " 'water': 112,\n",
       " 'second': 113,\n",
       " 'heathrow': 114,\n",
       " 'westagard': 115,\n",
       " 'rolled': 116,\n",
       " 'callback': 117,\n",
       " 'defibrillator': 118,\n",
       " 'anotherdisappointment': 119,\n",
       " 'tweeted': 120,\n",
       " 'signed': 121,\n",
       " 'jop': 122,\n",
       " 'amt': 123,\n",
       " 'headed': 124,\n",
       " 'management': 125,\n",
       " 'imo': 126,\n",
       " 'mintyfresh': 127,\n",
       " 'claims': 128,\n",
       " 'rectified': 129,\n",
       " 'updates': 130,\n",
       " 'glasses': 131,\n",
       " 'capabilities': 132,\n",
       " 'heinekenusacorp': 133,\n",
       " 'jamie': 134,\n",
       " 'pita': 135,\n",
       " 'still': 136,\n",
       " 'literally': 137,\n",
       " 'unimpressed': 138,\n",
       " 'everyone': 139,\n",
       " 'tickets': 140,\n",
       " 'tammy': 141,\n",
       " 'named': 142,\n",
       " 'misconnected': 143,\n",
       " 'ntuix': 144,\n",
       " 'habitrails': 145,\n",
       " 'performance': 146,\n",
       " 'jac': 147,\n",
       " 'bussines': 148,\n",
       " 'tkt': 149,\n",
       " 'bundle': 150,\n",
       " 'clearing': 151,\n",
       " 'rumors': 152,\n",
       " 'lauren': 153,\n",
       " 'disrespect': 154,\n",
       " 'underweight': 155,\n",
       " 'haul': 156,\n",
       " 'vacatinn': 157,\n",
       " 'waiver': 158,\n",
       " 'carrieunderwood': 159,\n",
       " 'departure': 160,\n",
       " 'rbn': 161,\n",
       " 'ratings': 162,\n",
       " 'wc': 163,\n",
       " 'grrwaaa': 164,\n",
       " 'talk': 165,\n",
       " 'limits': 166,\n",
       " 'sock': 167,\n",
       " 'fresh': 168,\n",
       " 'sabe': 169,\n",
       " 'accuratetraveltimes': 170,\n",
       " 'natural': 171,\n",
       " 'yet': 172,\n",
       " 'admiral': 173,\n",
       " 'special': 174,\n",
       " 'state': 175,\n",
       " 'standing': 176,\n",
       " 'pair': 177,\n",
       " 'acceptable': 178,\n",
       " 'gold': 179,\n",
       " 'momsgoodeats': 180,\n",
       " 'failed': 181,\n",
       " 'coachgs': 182,\n",
       " 'competitors': 183,\n",
       " 'foreign': 184,\n",
       " 'sooooo': 185,\n",
       " 'tonite': 186,\n",
       " 'needtocatchmynextflight': 187,\n",
       " 'stressful': 188,\n",
       " 'has': 189,\n",
       " 'complains': 190,\n",
       " 'amazed': 191,\n",
       " 'specifically': 192,\n",
       " 'keepusguessing': 193,\n",
       " 'giant': 194,\n",
       " 'nearly': 195,\n",
       " 'cgwe': 196,\n",
       " 'gpu': 197,\n",
       " 'eatgregeat': 198,\n",
       " 'product': 199,\n",
       " 'gills': 200,\n",
       " 'cheesy': 201,\n",
       " 'crap': 202,\n",
       " 'disrupted': 203,\n",
       " 'notes': 204,\n",
       " 'xxy': 205,\n",
       " 'res': 206,\n",
       " 'drw': 207,\n",
       " 'droppeditoffyet': 208,\n",
       " 'approve': 209,\n",
       " 'dfpietra': 210,\n",
       " 'amp': 211,\n",
       " 'ft': 212,\n",
       " 'announcer': 213,\n",
       " 'rerouted': 214,\n",
       " 'kickin': 215,\n",
       " 'stillwaiting': 216,\n",
       " 'extraordinaire': 217,\n",
       " 'ord': 218,\n",
       " 'younger': 219,\n",
       " 'el': 220,\n",
       " 'holdon': 221,\n",
       " 'five': 222,\n",
       " 'dramatically': 223,\n",
       " 'malfunction': 224,\n",
       " 'password': 225,\n",
       " 'zouowgv': 226,\n",
       " 'switched': 227,\n",
       " 'damionflight': 228,\n",
       " 'impress': 229,\n",
       " 'newlifetimecustomer': 230,\n",
       " 'volunteers': 231,\n",
       " 'mosaic': 232,\n",
       " 'impressed': 233,\n",
       " 'unrivalled': 234,\n",
       " 'jewel': 235,\n",
       " 'ak': 236,\n",
       " 'norma': 237,\n",
       " 'wmass': 238,\n",
       " 'inconvenient': 239,\n",
       " 'fixing': 240,\n",
       " 'assign': 241,\n",
       " 'hearing': 242,\n",
       " 'easy': 243,\n",
       " 'bound': 244,\n",
       " 'unitedflightsever': 245,\n",
       " 'yourock': 246,\n",
       " 'intercom': 247,\n",
       " 'ric': 248,\n",
       " 'herself': 249,\n",
       " 'pants': 250,\n",
       " 'agree': 251,\n",
       " 'spread': 252,\n",
       " 'peterstraubmma': 253,\n",
       " 'reinstated': 254,\n",
       " 'me': 255,\n",
       " 'obsessed': 256,\n",
       " 'elizabeth': 257,\n",
       " 'avalible': 258,\n",
       " 'lindsey': 259,\n",
       " 'volume': 260,\n",
       " 'responses': 261,\n",
       " 'spent': 262,\n",
       " 'elevategold': 263,\n",
       " 'gets': 264,\n",
       " 'promotion': 265,\n",
       " 'submit': 266,\n",
       " 'whoooo': 267,\n",
       " 'doing': 268,\n",
       " 'comedy': 269,\n",
       " 'soulandinspiration': 270,\n",
       " 'roger': 271,\n",
       " 'disney': 272,\n",
       " 'detail': 273,\n",
       " 'exasperating': 274,\n",
       " 'xhlc': 275,\n",
       " 'questions': 276,\n",
       " 'ran': 277,\n",
       " 'daystogo': 278,\n",
       " 'notcomingback': 279,\n",
       " 'domestic': 280,\n",
       " 'plan': 281,\n",
       " 'aircrft': 282,\n",
       " 'taiwan': 283,\n",
       " 'anytime': 284,\n",
       " 'freddie': 285,\n",
       " 'somewhat': 286,\n",
       " 'congrats': 287,\n",
       " 'exicted': 288,\n",
       " 'stains': 289,\n",
       " 'freakin': 290,\n",
       " 'jfk': 291,\n",
       " 'scheduled': 292,\n",
       " 'existing': 293,\n",
       " 'gcks': 294,\n",
       " 'gig': 295,\n",
       " 'left': 296,\n",
       " 'invited': 297,\n",
       " 'invest': 298,\n",
       " 'hotels': 299,\n",
       " 'enoughisenough': 300,\n",
       " 'suntoshi': 301,\n",
       " 'tropic': 302,\n",
       " 'tcqx': 303,\n",
       " 'flintstone': 304,\n",
       " 'worked': 305,\n",
       " 'delay': 306,\n",
       " 'appleton': 307,\n",
       " 'o': 308,\n",
       " 'cnn': 309,\n",
       " 'fritz': 310,\n",
       " 'traffic': 311,\n",
       " 'monitor': 312,\n",
       " 'sleet': 313,\n",
       " 'fedup': 314,\n",
       " 'screen': 315,\n",
       " 'inspired': 316,\n",
       " 'tuned': 317,\n",
       " 'flightlation': 318,\n",
       " 'va': 319,\n",
       " 'qf': 320,\n",
       " 'alb': 321,\n",
       " 'friends': 322,\n",
       " 'ivgpzsjtkw': 323,\n",
       " 'worm': 324,\n",
       " 'atlantic': 325,\n",
       " 'px': 326,\n",
       " 'livethelegend': 327,\n",
       " 'ads': 328,\n",
       " 'tech': 329,\n",
       " 'comparison': 330,\n",
       " 'galley': 331,\n",
       " 'divadapouch': 332,\n",
       " 'divert': 333,\n",
       " 'tracking': 334,\n",
       " 'toward': 335,\n",
       " 'vpqem': 336,\n",
       " 'reopens': 337,\n",
       " 'tea': 338,\n",
       " 'littlebirds': 339,\n",
       " 'doubt': 340,\n",
       " 'sbn': 341,\n",
       " 'wbzorrn': 342,\n",
       " 'ionlyflyblue': 343,\n",
       " 'rd': 344,\n",
       " 'thx': 345,\n",
       " 'slapintheface': 346,\n",
       " 'crazy': 347,\n",
       " 'sucking': 348,\n",
       " 'warriors': 349,\n",
       " 'abcletjetbluestreamfeed': 350,\n",
       " 'whatstheholdup': 351,\n",
       " 'steve': 352,\n",
       " 'deserve': 353,\n",
       " 'bums': 354,\n",
       " 'singapore': 355,\n",
       " 'jetbluesofly': 356,\n",
       " 'friendlysky': 357,\n",
       " 'mgr': 358,\n",
       " 'accident': 359,\n",
       " 'emptied': 360,\n",
       " 'ohare': 361,\n",
       " 'exposed': 362,\n",
       " 'card': 363,\n",
       " 'nd': 364,\n",
       " 'dealt': 365,\n",
       " 'nrt': 366,\n",
       " 'act': 367,\n",
       " 'sombrons': 368,\n",
       " 'awful': 369,\n",
       " 'fuck': 370,\n",
       " 'reassign': 371,\n",
       " 'oscarnight': 372,\n",
       " 'dz': 373,\n",
       " 'leaving': 374,\n",
       " 'insanely': 375,\n",
       " 'thats': 376,\n",
       " 'nature': 377,\n",
       " 'sent': 378,\n",
       " 'pathetic': 379,\n",
       " 'cost': 380,\n",
       " 'comment': 381,\n",
       " 'throug': 382,\n",
       " 'woohoo': 383,\n",
       " 'tsvibtvt': 384,\n",
       " 'belabor': 385,\n",
       " 'dog': 386,\n",
       " 'seat': 387,\n",
       " 'upcoming': 388,\n",
       " 'patient': 389,\n",
       " 'champagne': 390,\n",
       " 'whose': 391,\n",
       " 'fat': 392,\n",
       " 'branding': 393,\n",
       " 'jdvk': 394,\n",
       " 'truebluecolors': 395,\n",
       " 'read': 396,\n",
       " 'nonstop': 397,\n",
       " 'directional': 398,\n",
       " 'resolving': 399,\n",
       " 'props': 400,\n",
       " 'rude': 401,\n",
       " 'wont': 402,\n",
       " 'freezing': 403,\n",
       " 'wht': 404,\n",
       " 'friendlyfriday': 405,\n",
       " 'dartmedia': 406,\n",
       " 'keulg': 407,\n",
       " 'jblu': 408,\n",
       " 'unsympathetic': 409,\n",
       " 'breach': 410,\n",
       " 'leadership': 411,\n",
       " 'screwed': 412,\n",
       " 'thankgoodness': 413,\n",
       " 'aka': 414,\n",
       " 'donut': 415,\n",
       " 'momma': 416,\n",
       " 'safety': 417,\n",
       " 'third': 418,\n",
       " 'corevalues': 419,\n",
       " 'traditions': 420,\n",
       " 'beefjerky': 421,\n",
       " 'yourselves': 422,\n",
       " 'sat': 423,\n",
       " 'recommendation': 424,\n",
       " 'beverages': 425,\n",
       " 'total': 426,\n",
       " 'lostluggage': 427,\n",
       " 'inquired': 428,\n",
       " 'they': 429,\n",
       " 'ppva': 430,\n",
       " 'unitedsucks': 431,\n",
       " 'byod': 432,\n",
       " 'poor': 433,\n",
       " 'costumerservice': 434,\n",
       " 'replying': 435,\n",
       " 'disappeared': 436,\n",
       " 'fi': 437,\n",
       " 'brands': 438,\n",
       " 'beach': 439,\n",
       " 'efficiency': 440,\n",
       " 'books': 441,\n",
       " 'hemispheresmag': 442,\n",
       " 'dicks': 443,\n",
       " 'promptly': 444,\n",
       " 'greeeaat': 445,\n",
       " 'grouchy': 446,\n",
       " 'cust': 447,\n",
       " 'stingiest': 448,\n",
       " 'otfz': 449,\n",
       " 'currently': 450,\n",
       " 'alot': 451,\n",
       " 'likes': 452,\n",
       " 'decent': 453,\n",
       " 'last': 454,\n",
       " 'southwestluv': 455,\n",
       " 'situation': 456,\n",
       " 'tbd': 457,\n",
       " 'cyd': 458,\n",
       " 'surprised': 459,\n",
       " 'disabledtraveler': 460,\n",
       " 'li': 461,\n",
       " 'virginatlantic': 462,\n",
       " 'remembering': 463,\n",
       " 'flightations': 464,\n",
       " 'question': 465,\n",
       " 'deborah': 466,\n",
       " 'timing': 467,\n",
       " 'lil': 468,\n",
       " 'gcwvfuopl': 469,\n",
       " 'young': 470,\n",
       " 'departs': 471,\n",
       " 'surf': 472,\n",
       " 'plus': 473,\n",
       " 'atc': 474,\n",
       " 'own': 475,\n",
       " 'mxo': 476,\n",
       " 'nope': 477,\n",
       " 'condition': 478,\n",
       " 'return': 479,\n",
       " 'iadore': 480,\n",
       " 'fidencio': 481,\n",
       " 'security': 482,\n",
       " 'passenegers': 483,\n",
       " 'velourlive': 484,\n",
       " 'ct': 485,\n",
       " 'segs': 486,\n",
       " 'timezones': 487,\n",
       " 'hotel': 488,\n",
       " 'reuniting': 489,\n",
       " 'beantownmatty': 490,\n",
       " 'hundred': 491,\n",
       " 'boom': 492,\n",
       " 'robotweeting': 493,\n",
       " 'commute': 494,\n",
       " 'lift': 495,\n",
       " 'cheaper': 496,\n",
       " 'emailed': 497,\n",
       " 'elp': 498,\n",
       " 'called': 499,\n",
       " 'additionally': 500,\n",
       " 'departing': 501,\n",
       " 'tsa': 502,\n",
       " 'averted': 503,\n",
       " 'overwhelmed': 504,\n",
       " 'zfqmpgxvs': 505,\n",
       " 'drive': 506,\n",
       " 'bingo': 507,\n",
       " 'ohokl': 508,\n",
       " 'omg': 509,\n",
       " 'loving': 510,\n",
       " 'trip': 511,\n",
       " 'sju': 512,\n",
       " 'cot': 513,\n",
       " 'helps': 514,\n",
       " 'karajusto': 515,\n",
       " 'darn': 516,\n",
       " 'fsd': 517,\n",
       " 'meetthefleet': 518,\n",
       " 'tkx': 519,\n",
       " 'hotspot': 520,\n",
       " 'rollerboards': 521,\n",
       " 'spirit': 522,\n",
       " 'non': 523,\n",
       " 'couldn': 524,\n",
       " 'lifetime': 525,\n",
       " 'north': 526,\n",
       " 'jb': 527,\n",
       " 'boldflavors': 528,\n",
       " 'threw': 529,\n",
       " 'comcast': 530,\n",
       " 'shots': 531,\n",
       " 'vdfdodqvgx': 532,\n",
       " 'classy': 533,\n",
       " 'thailand': 534,\n",
       " 'returning': 535,\n",
       " 'did': 536,\n",
       " 'michaelbcoleman': 537,\n",
       " 'mandarinjourney': 538,\n",
       " 'flightlations': 539,\n",
       " 'minimal': 540,\n",
       " 'raised': 541,\n",
       " 'nustgpelsf': 542,\n",
       " 'kfuyyokufv': 543,\n",
       " 'iimtjxcvlg': 544,\n",
       " 'fcmostinnovative': 545,\n",
       " 'pennypincher': 546,\n",
       " 'wiyh': 547,\n",
       " 'lacking': 548,\n",
       " 'bloody': 549,\n",
       " 'veggies': 550,\n",
       " 'hartford': 551,\n",
       " 'follow': 552,\n",
       " 'gbiw': 553,\n",
       " 'brandi': 554,\n",
       " 'indy': 555,\n",
       " 'repaid': 556,\n",
       " 'earned': 557,\n",
       " 'mistakes': 558,\n",
       " 'nfaqhhr': 559,\n",
       " 'memo': 560,\n",
       " 'arose': 561,\n",
       " 'pressurecooker': 562,\n",
       " 'pass': 563,\n",
       " 'ipad': 564,\n",
       " 'written': 565,\n",
       " 'blue': 566,\n",
       " 'expects': 567,\n",
       " 'mvp': 568,\n",
       " 'inches': 569,\n",
       " 'make': 570,\n",
       " 'investigate': 571,\n",
       " 'workforce': 572,\n",
       " 'luggages': 573,\n",
       " 'dirtiest': 574,\n",
       " 'jose': 575,\n",
       " 'connex': 576,\n",
       " 'hpn': 577,\n",
       " 'noair': 578,\n",
       " 'accruing': 579,\n",
       " 'oreos': 580,\n",
       " 'disgrace': 581,\n",
       " 'lack': 582,\n",
       " 'japan': 583,\n",
       " 'fan': 584,\n",
       " 'refreshes': 585,\n",
       " 'subtlety': 586,\n",
       " 'yxn': 587,\n",
       " 'diversion': 588,\n",
       " 'brushing': 589,\n",
       " 'heavily': 590,\n",
       " 'yeehaw': 591,\n",
       " 'happycustomer': 592,\n",
       " 'palm': 593,\n",
       " 'membership': 594,\n",
       " 'transatlantic': 595,\n",
       " 'worded': 596,\n",
       " 'forget': 597,\n",
       " 'videos': 598,\n",
       " 'melissaafrancis': 599,\n",
       " 'thehipmunk': 600,\n",
       " 'cx': 601,\n",
       " 'qol': 602,\n",
       " 'robin': 603,\n",
       " 'quoted': 604,\n",
       " 'bs': 605,\n",
       " 'here': 606,\n",
       " 'exhausting': 607,\n",
       " 'funny': 608,\n",
       " 'without': 609,\n",
       " 'disconnected': 610,\n",
       " 'unanswered': 611,\n",
       " 'denairport': 612,\n",
       " 'veterans': 613,\n",
       " 'dedication': 614,\n",
       " 'compassionate': 615,\n",
       " 'freaky': 616,\n",
       " 'operate': 617,\n",
       " 'tiredcustomer': 618,\n",
       " 'colored': 619,\n",
       " 'disneyprincesshalfmarathon': 620,\n",
       " 'fare': 621,\n",
       " 'suppose': 622,\n",
       " 'every': 623,\n",
       " 'record': 624,\n",
       " 'tpallini': 625,\n",
       " 'worrying': 626,\n",
       " 'any': 627,\n",
       " 'fine': 628,\n",
       " 'recap': 629,\n",
       " 'corporation': 630,\n",
       " 'wake': 631,\n",
       " 'justgetmehome': 632,\n",
       " 'newplanesmell': 633,\n",
       " 'flyeia': 634,\n",
       " 'jp': 635,\n",
       " 'junction': 636,\n",
       " 'iljaebv': 637,\n",
       " 'suggested': 638,\n",
       " 'ethan': 639,\n",
       " 'martha': 640,\n",
       " 'big': 641,\n",
       " 'bit': 642,\n",
       " 'nqh': 643,\n",
       " 'peopleon': 644,\n",
       " 'rockinwellness': 645,\n",
       " 'beatriz': 646,\n",
       " 'calgary': 647,\n",
       " 'wv': 648,\n",
       " 'browser': 649,\n",
       " 'norway': 650,\n",
       " 'unitedairlines': 651,\n",
       " 'fwiw': 652,\n",
       " 'history': 653,\n",
       " 'canadian': 654,\n",
       " 'idnumber': 655,\n",
       " 'lbcncr': 656,\n",
       " 'shown': 657,\n",
       " 'cherry': 658,\n",
       " 'wheelsup': 659,\n",
       " 'freecomedyshow': 660,\n",
       " 'working': 661,\n",
       " 'dm': 662,\n",
       " 'adding': 663,\n",
       " 'kicked': 664,\n",
       " 'ritz': 665,\n",
       " 'smiling': 666,\n",
       " 'cheertymedad': 667,\n",
       " 'passes': 668,\n",
       " 'sometimes': 669,\n",
       " 'folks': 670,\n",
       " 'prgysvurm': 671,\n",
       " 'flightncy': 672,\n",
       " 'those': 673,\n",
       " 'battles': 674,\n",
       " 'despicable': 675,\n",
       " 'pray': 676,\n",
       " 'epicfail': 677,\n",
       " 'cs': 678,\n",
       " 'public': 679,\n",
       " 'ifc': 680,\n",
       " 'miscalculation': 681,\n",
       " 'hou': 682,\n",
       " 'dos': 683,\n",
       " 'bio': 684,\n",
       " 'authoritative': 685,\n",
       " 'phxskyharbor': 686,\n",
       " 'panicked': 687,\n",
       " 'optimistic': 688,\n",
       " 'sincerely': 689,\n",
       " 'poorcustomerservice': 690,\n",
       " 'crutches': 691,\n",
       " 'rps': 692,\n",
       " 'cousins': 693,\n",
       " 'woman': 694,\n",
       " 'lauderdale': 695,\n",
       " 'planning': 696,\n",
       " 'unhappy': 697,\n",
       " 'bc': 698,\n",
       " 'entire': 699,\n",
       " 'ear': 700,\n",
       " 'surprisingly': 701,\n",
       " 'savannah': 702,\n",
       " 'hour': 703,\n",
       " 'know': 704,\n",
       " 'fraction': 705,\n",
       " 'happened': 706,\n",
       " 'awfulness': 707,\n",
       " 'sooner': 708,\n",
       " 'authors': 709,\n",
       " 'calderon': 710,\n",
       " 'ftlzwtvo': 711,\n",
       " 'gracious': 712,\n",
       " 'fourth': 713,\n",
       " 'okc': 714,\n",
       " 'lbb': 715,\n",
       " 'lol': 716,\n",
       " 'na': 717,\n",
       " 'most': 718,\n",
       " 'birthday': 719,\n",
       " 'pressure': 720,\n",
       " 'tacky': 721,\n",
       " 'patches': 722,\n",
       " 'ozs': 723,\n",
       " 'wtfodds': 724,\n",
       " 'planned': 725,\n",
       " 'buzj': 726,\n",
       " 'goods': 727,\n",
       " 'equipment': 728,\n",
       " 'degree': 729,\n",
       " 'trying': 730,\n",
       " 'seriousness': 731,\n",
       " 'barbara': 732,\n",
       " 'myers': 733,\n",
       " 'everytime': 734,\n",
       " 'tiffany': 735,\n",
       " 'temps': 736,\n",
       " 'significantly': 737,\n",
       " 'sites': 738,\n",
       " 'week': 739,\n",
       " 'philadelphia': 740,\n",
       " 'settle': 741,\n",
       " 'operating': 742,\n",
       " 'notifying': 743,\n",
       " 'peace': 744,\n",
       " 'clean': 745,\n",
       " 'goldentickets': 746,\n",
       " 'owner': 747,\n",
       " 'nasty': 748,\n",
       " 'trained': 749,\n",
       " 'sz': 750,\n",
       " 'takeoff': 751,\n",
       " 'wasappreciated': 752,\n",
       " 'sunrise': 753,\n",
       " 'xqaqb': 754,\n",
       " 'flies': 755,\n",
       " 'edinburgh': 756,\n",
       " 'terriblecustomerservice': 757,\n",
       " 'motel': 758,\n",
       " 'engagement': 759,\n",
       " 'qd': 760,\n",
       " 'equal': 761,\n",
       " 'expeditious': 762,\n",
       " 'flyswa': 763,\n",
       " 'match': 764,\n",
       " 'classiq': 765,\n",
       " 'herman': 766,\n",
       " 'stacycrossb': 767,\n",
       " 'hate': 768,\n",
       " 'ef': 769,\n",
       " 'i': 770,\n",
       " 'aarp': 771,\n",
       " 'hotelliving': 772,\n",
       " 'needed': 773,\n",
       " 'sunshine': 774,\n",
       " 'remedy': 775,\n",
       " 'ever': 776,\n",
       " 'dms': 777,\n",
       " 'guaranteed': 778,\n",
       " 'medical': 779,\n",
       " 'gaga': 780,\n",
       " 'headaches': 781,\n",
       " 'mean': 782,\n",
       " 'dietcoke': 783,\n",
       " 'dajwzhlvyu': 784,\n",
       " 'appreciated': 785,\n",
       " 'race': 786,\n",
       " 'handedly': 787,\n",
       " 'sato': 788,\n",
       " 'bizarre': 789,\n",
       " 'yup': 790,\n",
       " 'vent': 791,\n",
       " 'cxcld': 792,\n",
       " 'lies': 793,\n",
       " 'continues': 794,\n",
       " 'sue': 795,\n",
       " 'page': 796,\n",
       " 'hahah': 797,\n",
       " 'dance': 798,\n",
       " 'wheelchairs': 799,\n",
       " 'ua': 800,\n",
       " 'customerservicewin': 801,\n",
       " 'pull': 802,\n",
       " 'thtime': 803,\n",
       " 'par': 804,\n",
       " 'ex': 805,\n",
       " 'carousel': 806,\n",
       " 'ignored': 807,\n",
       " 'walking': 808,\n",
       " 'bostongarden': 809,\n",
       " 'btv': 810,\n",
       " 'forum': 811,\n",
       " 'money': 812,\n",
       " 'umosaicmecrazy': 813,\n",
       " 'felt': 814,\n",
       " 'nocompensation': 815,\n",
       " 'offers': 816,\n",
       " 'provide': 817,\n",
       " 'knack': 818,\n",
       " 'poorly': 819,\n",
       " 'indianapolis': 820,\n",
       " 'crews': 821,\n",
       " 'shrug': 822,\n",
       " 'views': 823,\n",
       " 'oma': 824,\n",
       " 'disneyworld': 825,\n",
       " 'pretty': 826,\n",
       " 'somehow': 827,\n",
       " 'yr': 828,\n",
       " 'roanoke': 829,\n",
       " 'ferrissalameh': 830,\n",
       " 'aweful': 831,\n",
       " 'presenting': 832,\n",
       " 'stressors': 833,\n",
       " 'destinationdragons': 834,\n",
       " 'outage': 835,\n",
       " 'waivers': 836,\n",
       " 'arizona': 837,\n",
       " 'holidays': 838,\n",
       " 'isml': 839,\n",
       " 'pb': 840,\n",
       " 'random': 841,\n",
       " 'listening': 842,\n",
       " 'outrageous': 843,\n",
       " 'hubby': 844,\n",
       " 'gz': 845,\n",
       " 'jh': 846,\n",
       " 'incentive': 847,\n",
       " 'connects': 848,\n",
       " 'loyalmosaicmember': 849,\n",
       " 'whatever': 850,\n",
       " 'abundance': 851,\n",
       " 'cold': 852,\n",
       " 'processed': 853,\n",
       " 'exhausted': 854,\n",
       " 'recovering': 855,\n",
       " 'error': 856,\n",
       " 'agreement': 857,\n",
       " 'panam': 858,\n",
       " 'vp': 859,\n",
       " 'west': 860,\n",
       " 'nancy': 861,\n",
       " 'efficient': 862,\n",
       " 'beanie': 863,\n",
       " 'talking': 864,\n",
       " 'lugging': 865,\n",
       " 'rayja': 866,\n",
       " 'fault': 867,\n",
       " 'panic': 868,\n",
       " 'aging': 869,\n",
       " 'happiness': 870,\n",
       " 'reviewed': 871,\n",
       " 'proportion': 872,\n",
       " 'border': 873,\n",
       " 'lightbulb': 874,\n",
       " 'slightly': 875,\n",
       " 'acfqcdq': 876,\n",
       " 'resources': 877,\n",
       " 'quite': 878,\n",
       " 'alone': 879,\n",
       " 'horrible': 880,\n",
       " 'faces': 881,\n",
       " 'stillnobags': 882,\n",
       " 'defend': 883,\n",
       " 'newflight': 884,\n",
       " 'formally': 885,\n",
       " 'decisions': 886,\n",
       " 'dope': 887,\n",
       " 'xuq': 888,\n",
       " 'chair': 889,\n",
       " 'func': 890,\n",
       " 'dimmed': 891,\n",
       " 'recognized': 892,\n",
       " 'valued': 893,\n",
       " 'tv': 894,\n",
       " 'crashed': 895,\n",
       " 'transpacific': 896,\n",
       " 'eri': 897,\n",
       " 'dakak': 898,\n",
       " 'all': 899,\n",
       " 'regret': 900,\n",
       " 'sjc': 901,\n",
       " 'difficulty': 902,\n",
       " 'emery': 903,\n",
       " 'misread': 904,\n",
       " 'breakfast': 905,\n",
       " 'wallet': 906,\n",
       " 'flightd': 907,\n",
       " 'unanticipated': 908,\n",
       " 'affordable': 909,\n",
       " 'cheap': 910,\n",
       " 'hearts': 911,\n",
       " 'harder': 912,\n",
       " 'accountable': 913,\n",
       " 'xmz': 914,\n",
       " 'comm': 915,\n",
       " 'stl': 916,\n",
       " 'concern': 917,\n",
       " 'texas': 918,\n",
       " 'dept': 919,\n",
       " 'furious': 920,\n",
       " 'aneqxzr': 921,\n",
       " 'saxonandparole': 922,\n",
       " 'advertised': 923,\n",
       " 'robcnyc': 924,\n",
       " 'shampoo': 925,\n",
       " 'inefficiency': 926,\n",
       " 'commitment': 927,\n",
       " 'alwaysdelayedonunited': 928,\n",
       " 'flipping': 929,\n",
       " 'ukdjjijrow': 930,\n",
       " 'tomorrow': 931,\n",
       " 'aaron': 932,\n",
       " 'days': 933,\n",
       " 'urgency': 934,\n",
       " 'shall': 935,\n",
       " 'happyflier': 936,\n",
       " 'overcharged': 937,\n",
       " 'decorum': 938,\n",
       " 'suuuuper': 939,\n",
       " 'gottogetbetter': 940,\n",
       " 'dollar': 941,\n",
       " 'hipunis': 942,\n",
       " 'reimbursed': 943,\n",
       " 'pet': 944,\n",
       " 'lpdstock': 945,\n",
       " 'goodness': 946,\n",
       " 'transit': 947,\n",
       " 'official': 948,\n",
       " 'connect': 949,\n",
       " 'eight': 950,\n",
       " 'straight': 951,\n",
       " 'princess': 952,\n",
       " 'sba': 953,\n",
       " 'airways': 954,\n",
       " 'final': 955,\n",
       " 'shift': 956,\n",
       " 'flights': 957,\n",
       " 'note': 958,\n",
       " 'iove': 959,\n",
       " 'conflict': 960,\n",
       " 'announce': 961,\n",
       " 'pricing': 962,\n",
       " 'choices': 963,\n",
       " 'white': 964,\n",
       " 'gbostu': 965,\n",
       " 'pitt': 966,\n",
       " 'missedupgrades': 967,\n",
       " 'dinner': 968,\n",
       " 'inevitable': 969,\n",
       " 'diverted': 970,\n",
       " 'americanairlines': 971,\n",
       " 'corrected': 972,\n",
       " 'quality': 973,\n",
       " 'apologize': 974,\n",
       " 'hayleymad': 975,\n",
       " 'damn': 976,\n",
       " 'really': 977,\n",
       " 'marketing': 978,\n",
       " 'outfitted': 979,\n",
       " 'wyoming': 980,\n",
       " 'dadboner': 981,\n",
       " 'explore': 982,\n",
       " 'qjkl': 983,\n",
       " 'roc': 984,\n",
       " 'hail': 985,\n",
       " 'man': 986,\n",
       " 'nawww': 987,\n",
       " 'qdebyahqfm': 988,\n",
       " 'treatment': 989,\n",
       " 'platter': 990,\n",
       " 'nonworking': 991,\n",
       " 'concrete': 992,\n",
       " 'dewithpew': 993,\n",
       " 'bounce': 994,\n",
       " 'victim': 995,\n",
       " 'unaccounted': 996,\n",
       " 'gift': 997,\n",
       " 'booze': 998,\n",
       " 'notfair': 999,\n",
       " 'kvkd': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ok = data.text = data.text.apply(lambda x : [word_index.get(word,0) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(x) for x in data_ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ok = keras.preprocessing.sequence.pad_sequences(data_ok.values,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4726, 40)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ok.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Embedding(max_word,50,input_length = max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.LSTM(64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 50)            355000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                29440     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 384,505\n",
      "Trainable params: 384,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3780 samples, validate on 946 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From d:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      " 896/3780 [======>.......................] - ETA: 5s - loss: 0.6885 - acc: 0.5279"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " indices[111,38] = 7100 is not in [0, 7100)\n\t [[node sequential/embedding/embedding_lookup (defined at d:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_3452]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-f90ce79b113a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_ok\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32md:\\develop\\python\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  indices[111,38] = 7100 is not in [0, 7100)\n\t [[node sequential/embedding/embedding_lookup (defined at d:\\develop\\python\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_3452]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "model.fit(data_ok,data.review.values,epochs=10,batch_size=128,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
